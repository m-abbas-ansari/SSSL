{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "class args:\n",
    "    seed = 41\n",
    "    epochs=1000\n",
    "    batch_size= 32\n",
    "    img_height = 224\n",
    "    img_width = 224\n",
    "    ffn_size = 512\n",
    "    workers= 1\n",
    "    learning_rate_weights=0.2\n",
    "    learning_rate_biases=0.0048\n",
    "    weight_decay=1e-6\n",
    "    lambd=0.0051\n",
    "    projector=[ffn_size*16]*3\n",
    "    print_freq=100\n",
    "    checkpoint_dir=Path('../checkpoint/')\n",
    "    data_dir = \"../../dataset/FULL_DATASET/FIXATION_DATASET\"\n",
    "    datasets = ['SALICON', 'EMOD', 'FIWI', 'MITLowRes', 'OSIE', 'SIENA12', 'TORONTO', 'VIU']\n",
    "    transform = dict(\n",
    "        img_size = (img_height, img_width),\n",
    "        noise = 0,\n",
    "        drop = 0,\n",
    "        reversal = 0,\n",
    "        rotation = 0,\n",
    "    )\n",
    "\n",
    "args = args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from PIL import Image\n",
    "from random import sample\n",
    "import numpy as np\n",
    "import torch.utils.data as data\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn.functional import pad\n",
    "import os\n",
    "\n",
    "def read_dataset(anno_dir, datasets, val_ratio = 0.2):\n",
    "    \"\"\"\n",
    "    We split each dataset in datasets list into train and val\n",
    "    \"\"\"\n",
    "    train_anno = {'fixation': [],\n",
    "                  'duration': [],\n",
    "                  'img_id': [],\n",
    "                  'dva': [],\n",
    "                  'img_size': []}\n",
    "    \n",
    "    val_anno = {'fixation': [],\n",
    "                'duration': [],\n",
    "                'img_id': [],\n",
    "                'dva': [],\n",
    "                'img_size': []}\n",
    "    \n",
    "    ret_anno = (train_anno, val_anno)\n",
    "    \n",
    "    for data in datasets:\n",
    "        anno = {}\n",
    "        with open(f\"{anno_dir}/ANNOTATIONS/{data}.json\", 'r') as f:\n",
    "            anno = json.load(f)\n",
    "        ims = list(anno.keys())\n",
    "        val_len = int(val_ratio * len(ims))\n",
    "        val_ims = sample(ims, val_len)\n",
    "        train_ims = list(set(ims) - set(val_ims))\n",
    "        \n",
    "        for i, g in enumerate((train_ims, val_ims)):\n",
    "            for im in g:\n",
    "                num = len(anno[im]['fixations'])\n",
    "                ret_anno[i]['fixation'].extend(anno[im]['fixations'])\n",
    "                if 'durations' in anno[im]:\n",
    "                    ret_anno[i]['duration'].extend(anno[im]['durations'])\n",
    "                else:\n",
    "                    ret_anno[i]['duration'].extend([[0]]*num)\n",
    "                    \n",
    "                ret_anno[i]['img_id'].extend([f\"{anno_dir}/STIMULI/{data}/{im}.jpg\"]*num)\n",
    "                if 'dva' in anno[im]:\n",
    "                    ret_anno[i]['dva'].extend([anno[im]['dva']]*num)\n",
    "                else:\n",
    "                    ret_anno[i]['dva'].extend([None]*num)\n",
    "                ret_anno[i]['img_size'].extend([anno[im]['img_size']]*num)\n",
    "    \n",
    "    return ret_anno\n",
    "\n",
    "class FixationDataset(data.Dataset):\n",
    "    def __init__(self, data, transform):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        assert os.exists(self.data['img_id'][index])\n",
    "        fix = np.array(self.data['fixation'][index].copy())\n",
    "        dur = np.array(self.data['duration'][index].copy())\n",
    "        dva = self.data['dva'][index]\n",
    "        \n",
    "        return None\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data['img_id'])\n",
    "    \n",
    "    def collate_function(self, batch):\n",
    "        v1_b, v2_b = zip(*batch)\n",
    "        return self.pad_batch(v1_b), self.pad_batch(v2_b)\n",
    "\n",
    "    def pad_batch(self, batch):\n",
    "        img_b, fix_b, dur_b = zip(*batch)\n",
    "        fix_b, dur_b = list(fix_b), list(dur_b)\n",
    "        fix_lens = [len(fix) for fix in fix_b]\n",
    "        max_fix_len = max(fix_lens)\n",
    "\n",
    "        for i, fix in enumerate(fix_b):\n",
    "            fix_b[i] = pad(fix, (0,0, 0, max_fix_len - len(fix)), \"constant\", 1e7)\n",
    "            dur_b[i] = pad(dur_b[i], (0,max_fix_len - len(dur_b[i])), \"constant\", 1e7)\n",
    "\n",
    "        return (torch.stack(img_b), torch.stack(fix_b), torch.stack(dur_b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "anno, _ = read_dataset(args.data_dir, args.datasets, val_ratio=0.0)\n",
    "# dataset = FixationDataset(anno)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(924584, 924584)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(anno['fixation']), len(anno['duration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(len(anno['fixation'])):\n",
    "    img_id = anno['img_id'][idx]\n",
    "    fix = anno['fixation'][idx]\n",
    "    dur = anno['duration'][idx]\n",
    "    \n",
    "    if not isinstance(dur, list): print(idx, img_id,fix,dur)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "908074",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43manno\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m908074\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 908074"
     ]
    }
   ],
   "source": [
    "anno[908074]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
